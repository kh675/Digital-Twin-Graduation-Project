{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Career Prediction Model\n",
    "\n",
    "This notebook builds a machine learning model to predict career paths for students based on:\n",
    "- Academic performance (GPA, attendance, grades)\n",
    "- Skill counts and course completion\n",
    "- Skill gap analysis from Step 2\n",
    "- Student embeddings (PCA-reduced)\n",
    "\n",
    "**Career Classes**: Data, Machine Learning, Cloud, Cybersecurity, Network, DevOps, Software, Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports & seeds\n",
    "import os, json, pickle, joblib, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"✅ Imports complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load data\n",
    "BASE = Path(\".\")\n",
    "\n",
    "# Load students dataset\n",
    "df = pd.read_csv(BASE / \"digital_twin_students_1500_cleaned.csv\")\n",
    "print(f\"Loaded {len(df)} students\")\n",
    "\n",
    "# Load skill gap profiles from Step 2\n",
    "with open(BASE / \"skill_gap_profiles\" / \"student_profiles.json\", \"r\") as f:\n",
    "    profiles = json.load(f)\n",
    "print(f\"Loaded {len(profiles)} profiles\")\n",
    "\n",
    "# Load student embeddings\n",
    "with open(BASE / \"embeddings\" / \"embeddings_students.pkl\", \"rb\") as f:\n",
    "    emb_data = pickle.load(f)\n",
    "    student_ids = emb_data['ids']\n",
    "    student_embeddings = np.vstack(emb_data['embeddings'])\n",
    "print(f\"Loaded embeddings: {student_embeddings.shape}\")\n",
    "\n",
    "print(\"\\n✅ Data loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Create career labels (pseudo-labels from top job matches)\n",
    "\n",
    "def map_job_to_class(job_title):\n",
    "    \"\"\"Map job title to one of 8 career classes\"\"\"\n",
    "    t = str(job_title).lower()\n",
    "    \n",
    "    if any(k in t for k in [\"data\", \"analyst\", \"data scientist\", \"etl\", \"big data\", \"data engineer\"]):\n",
    "        return \"Data\"\n",
    "    if any(k in t for k in [\"machine learning\", \"ml\", \"deep learning\", \"ai\", \"ml engineer\"]):\n",
    "        return \"Machine Learning\"\n",
    "    if any(k in t for k in [\"cloud\", \"aws\", \"azure\", \"gcp\", \"cloud engineer\", \"cloud architect\"]):\n",
    "        return \"Cloud\"\n",
    "    if any(k in t for k in [\"security\", \"cyber\", \"penetration\", \"infosec\", \"security analyst\"]):\n",
    "        return \"Cybersecurity\"\n",
    "    if any(k in t for k in [\"network\", \"routing\", \"switching\", \"network engineer\"]):\n",
    "        return \"Network\"\n",
    "    if any(k in t for k in [\"devops\", \"sre\", \"ci/cd\", \"infrastructure\"]):\n",
    "        return \"DevOps\"\n",
    "    if any(k in t for k in [\"developer\", \"software\", \"backend\", \"frontend\", \"full stack\", \"engineer\"]):\n",
    "        return \"Software\"\n",
    "    return \"Other\"\n",
    "\n",
    "# Build labels from profiles (top job match)\n",
    "label_rows = []\n",
    "profiles_map = {p['student_id']: p for p in profiles}\n",
    "\n",
    "for sid in df['StudentID'].astype(str).tolist():\n",
    "    p = profiles_map.get(sid, {})\n",
    "    top_job = None\n",
    "    \n",
    "    if p.get(\"best_job_matches\"):\n",
    "        item = p[\"best_job_matches\"][0]\n",
    "        top_job = item.get(\"job_title\") if isinstance(item, dict) else item\n",
    "    \n",
    "    label = map_job_to_class(top_job or \"\")\n",
    "    label_rows.append({'StudentID': sid, 'career_label': label})\n",
    "\n",
    "labels_df = pd.DataFrame(label_rows)\n",
    "df = df.merge(labels_df, on=\"StudentID\", how=\"left\")\n",
    "\n",
    "# Check label distribution\n",
    "print(\"\\nLabel Distribution:\")\n",
    "print(df['career_label'].value_counts())\n",
    "print(\"\\nLabel Percentages:\")\n",
    "print(df['career_label'].value_counts(normalize=True).round(3))\n",
    "\n",
    "print(\"\\n✅ Labels created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Feature engineering\n",
    "\n",
    "# 1. Academic features\n",
    "df['GPA'] = pd.to_numeric(df['GPA'], errors='coerce').fillna(df['GPA'].mean())\n",
    "df['AttendancePercent'] = pd.to_numeric(df.get('AttendancePercent', 0), errors='coerce').fillna(80)\n",
    "df['FailedCourses'] = pd.to_numeric(df.get('FailedCourses', 0), errors='coerce').fillna(0)\n",
    "\n",
    "# 2. Skill and course counts\n",
    "def list_count(cell):\n",
    "    \"\"\"Count items in semicolon/comma separated list\"\"\"\n",
    "    if pd.isna(cell): \n",
    "        return 0\n",
    "    s = str(cell).strip()\n",
    "    if s == \"\" or s.lower() == \"nan\": \n",
    "        return 0\n",
    "    return len([x for x in re.split(r'[;,|/]+', s) if x.strip()])\n",
    "\n",
    "df['num_skills'] = df.get('Skills', \"\").apply(list_count)\n",
    "df['num_courses_completed'] = df.get('CoursesCompleted', \"\").apply(list_count)\n",
    "\n",
    "# 3. Major average (from grade columns if available)\n",
    "subject_cols = [c for c in df.columns if c.lower().endswith(\"_grade\") or \"grade\" in c.lower()]\n",
    "if subject_cols:\n",
    "    df['major_avg'] = df[subject_cols].replace(-1, np.nan).mean(axis=1).fillna(df['GPA'])\n",
    "else:\n",
    "    df['major_avg'] = df['GPA']\n",
    "\n",
    "# 4. Gap features from Step 2 profiles\n",
    "def get_profile(sid):\n",
    "    return profiles_map.get(str(sid), {})\n",
    "\n",
    "df['num_missing_skills'] = df['StudentID'].apply(\n",
    "    lambda s: len(get_profile(s).get('skill_gaps', {}).get('missing_skills', []))\n",
    ")\n",
    "\n",
    "def top_priority_mean(sid):\n",
    "    arr = get_profile(sid).get('skill_gaps', {}).get('priority_skills', [])\n",
    "    if not arr: \n",
    "        return 0.0\n",
    "    vals = [x.get('priority_score', 0) for x in arr]\n",
    "    return float(np.mean(vals))\n",
    "\n",
    "df['top_missing_priority'] = df['StudentID'].apply(top_priority_mean)\n",
    "\n",
    "# 5. Align and reduce embeddings (PCA to 32 dims)\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Build mapping from embedding ids to embeddings\n",
    "emb_map = {str(sid): emb for sid, emb in zip(student_ids, student_embeddings)}\n",
    "\n",
    "# Create matrix aligned to df order\n",
    "emb_matrix = np.vstack([\n",
    "    emb_map.get(str(sid), np.zeros(student_embeddings.shape[1])) \n",
    "    for sid in df['StudentID']\n",
    "])\n",
    "\n",
    "# PCA reduction\n",
    "pca = PCA(n_components=32, random_state=42)\n",
    "emb_pca = pca.fit_transform(emb_matrix)\n",
    "print(f\"PCA explained variance: {pca.explained_variance_ratio_.sum():.3f}\")\n",
    "\n",
    "# Add PCA features to dataframe\n",
    "for i in range(emb_pca.shape[1]):\n",
    "    df[f'emb_pca_{i}'] = emb_pca[:, i]\n",
    "\n",
    "print(f\"\\n✅ Features created\")\n",
    "print(f\"Total features: {8 + 32} (8 academic/gap + 32 embedding)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Encode labels and train/test split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define feature columns\n",
    "feature_cols = [\n",
    "    'GPA', 'major_avg', 'AttendancePercent', 'FailedCourses',\n",
    "    'num_skills', 'num_courses_completed', \n",
    "    'num_missing_skills', 'top_missing_priority'\n",
    "] + [c for c in df.columns if c.startswith('emb_pca_')]\n",
    "\n",
    "# Prepare feature matrix and labels\n",
    "X = df[feature_cols].fillna(0)\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['career_label'].fillna('Other'))\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Classes: {le.classes_}\")\n",
    "print(f\"Number of classes: {len(le.classes_)}\")\n",
    "\n",
    "# Stratified train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain size: {len(X_train)}\")\n",
    "print(f\"Test size: {len(X_test)}\")\n",
    "\n",
    "# Verify no NaN or inf\n",
    "assert not np.any(np.isnan(X.values)), \"Found NaN values in features!\"\n",
    "assert np.isfinite(X.values).all(), \"Found inf values in features!\"\n",
    "\n",
    "print(\"\\n✅ Data prepared for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Train baseline models (RandomForest + XGBoost)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "print(\"Training RandomForest baseline...\")\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200, \n",
    "    class_weight='balanced', \n",
    "    random_state=42, \n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "yhat_rf = rf.predict(X_test)\n",
    "\n",
    "print(f\"\\nRandomForest Results:\")\n",
    "print(f\"  Accuracy: {accuracy_score(y_test, yhat_rf):.3f}\")\n",
    "print(f\"  Macro F1: {f1_score(y_test, yhat_rf, average='macro'):.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training XGBoost model...\")\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "xgb.fit(X_train, y_train)\n",
    "yhat_xgb = xgb.predict(X_test)\n",
    "\n",
    "print(f\"\\nXGBoost Results:\")\n",
    "print(f\"  Accuracy: {accuracy_score(y_test, yhat_xgb):.3f}\")\n",
    "print(f\"  Macro F1: {f1_score(y_test, yhat_xgb, average='macro'):.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\\nDetailed Classification Report (XGBoost):\")\n",
    "print(classification_report(y_test, yhat_xgb, target_names=le.classes_))\n",
    "\n",
    "print(\"\\n✅ Models trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Cross-validation (optional - for more robust evaluation)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print(\"Running 5-fold cross-validation on XGBoost...\")\n",
    "cv_scores = cross_val_score(\n",
    "    xgb, X, y, cv=5, scoring='f1_macro', n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f\"\\nCross-validation F1 scores: {cv_scores}\")\n",
    "print(f\"Mean CV F1: {cv_scores.mean():.3f} (+/- {cv_scores.std():.3f})\")\n",
    "\n",
    "print(\"\\n✅ Cross-validation complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Evaluation and confusion matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    xgb, X_test, y_test, \n",
    "    display_labels=le.classes_,\n",
    "    cmap='Blues',\n",
    "    xticks_rotation=45,\n",
    "    ax=ax\n",
    ")\n",
    "plt.title('Confusion Matrix - XGBoost Career Prediction')\n",
    "plt.tight_layout()\n",
    "plt.savefig('models/confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✅ Confusion matrix saved to models/confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Model explainability (SHAP)\n",
    "import shap\n",
    "\n",
    "print(\"Computing SHAP values (this may take a minute)...\")\n",
    "explainer = shap.TreeExplainer(xgb)\n",
    "sample_data = X_train.sample(200, random_state=42)\n",
    "shap_values = explainer.shap_values(sample_data)\n",
    "\n",
    "# Summary plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(\n",
    "    shap_values, \n",
    "    sample_data, \n",
    "    feature_names=X_train.columns,\n",
    "    show=False\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig('models/shap_summary.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Feature importance from model\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': xgb.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "print(\"\\n✅ SHAP analysis complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Save artifacts\n",
    "import os\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# Save model and transformers\n",
    "joblib.dump(xgb, \"models/career_model_xgb.pkl\")\n",
    "joblib.dump(le, \"models/label_encoder.pkl\")\n",
    "joblib.dump(pca, \"models/emb_pca.pkl\")\n",
    "joblib.dump(feature_cols, \"models/feature_list.pkl\")\n",
    "\n",
    "# Save feature matrix for API use\n",
    "features_all = df[['StudentID'] + feature_cols].copy()\n",
    "features_all.to_csv(\"models/features_all.csv\", index=False)\n",
    "\n",
    "# Save feature importance\n",
    "feature_importance.to_csv(\"models/feature_importance.csv\", index=False)\n",
    "\n",
    "print(\"✅ Artifacts saved to models/ directory:\")\n",
    "print(\"  - career_model_xgb.pkl\")\n",
    "print(\"  - label_encoder.pkl\")\n",
    "print(\"  - emb_pca.pkl\")\n",
    "print(\"  - feature_list.pkl\")\n",
    "print(\"  - features_all.csv\")\n",
    "print(\"  - feature_importance.csv\")\n",
    "print(\"  - confusion_matrix.png\")\n",
    "print(\"  - shap_summary.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Prediction function and examples\n",
    "\n",
    "def predict_career(student_id):\n",
    "    \"\"\"Predict career path for a single student\"\"\"\n",
    "    row = df[df['StudentID'] == str(student_id)]\n",
    "    \n",
    "    if row.shape[0] == 0:\n",
    "        return {\"student_id\": student_id, \"error\": \"student not found\"}\n",
    "    \n",
    "    X_row = row[feature_cols].fillna(0)\n",
    "    probs = xgb.predict_proba(X_row)[0]\n",
    "    idx = np.argmax(probs)\n",
    "    label = le.inverse_transform([idx])[0]\n",
    "    \n",
    "    # Get top 3 predictions\n",
    "    top3_idx = probs.argsort()[-3:][::-1]\n",
    "    top3 = [le.inverse_transform([i])[0] for i in top3_idx]\n",
    "    \n",
    "    prob_map = dict(zip(le.classes_, [float(p) for p in probs]))\n",
    "    \n",
    "    return {\n",
    "        \"student_id\": student_id,\n",
    "        \"predicted_career\": label,\n",
    "        \"confidence\": float(probs[idx]),\n",
    "        \"top_3_careers\": top3,\n",
    "        \"probabilities\": prob_map\n",
    "    }\n",
    "\n",
    "# Test predictions on sample students\n",
    "print(\"Sample Predictions:\\n\")\n",
    "sample_ids = df['StudentID'].sample(5, random_state=42).tolist()\n",
    "\n",
    "for sid in sample_ids:\n",
    "    result = predict_career(sid)\n",
    "    print(f\"Student {sid}:\")\n",
    "    print(f\"  Predicted: {result['predicted_career']} ({result['confidence']:.2%})\")\n",
    "    print(f\"  Top 3: {', '.join(result['top_3_careers'])}\")\n",
    "    print()\n",
    "\n",
    "print(\"\\n✅ Prediction function ready\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
