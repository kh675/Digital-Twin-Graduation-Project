{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Step 7: Clustering Engine - Interactive Analysis\n",
                "\n",
                "This notebook implements student clustering using:\n",
                "- Academic features (GPA, attendance)\n",
                "- Skill embeddings (PCA components)\n",
                "- Skill gaps\n",
                "- Career predictions\n",
                "\n",
                "**Algorithms**: KMeans, DBSCAN\n",
                "**Visualizations**: t-SNE, UMAP, 3D PCA"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import json\n",
                "import pickle\n",
                "from pathlib import Path\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.cluster import KMeans, DBSCAN\n",
                "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
                "from sklearn.metrics.pairwise import cosine_similarity\n",
                "from sklearn.manifold import TSNE\n",
                "from sklearn.decomposition import PCA\n",
                "from collections import Counter\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Try to import UMAP (optional)\n",
                "try:\n",
                "    import umap\n",
                "    UMAP_AVAILABLE = True\n",
                "    print(\"âœ“ UMAP available\")\n",
                "except ImportError:\n",
                "    UMAP_AVAILABLE = False\n",
                "    print(\"âš  UMAP not available (install with: pip install umap-learn)\")\n",
                "\n",
                "print(\"Libraries loaded successfully\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "BASE = Path(\".\")\n",
                "\n",
                "# Load features\n",
                "df_features = pd.read_csv(BASE / \"models\" / \"features_all.csv\")\n",
                "print(f\"Loaded {len(df_features)} student features\")\n",
                "\n",
                "# Load embeddings\n",
                "with open(BASE / \"embeddings\" / \"embeddings_students.pkl\", \"rb\") as f:\n",
                "    emb_students = pickle.load(f)\n",
                "print(f\"Loaded student embeddings: {type(emb_students)}\")\n",
                "\n",
                "# Load skill gap profiles\n",
                "with open(BASE / \"skill_gap_profiles\" / \"student_profiles.json\", \"r\") as f:\n",
                "    profiles = json.load(f)\n",
                "profiles_map = {p['student_id']: p for p in profiles}\n",
                "print(f\"Loaded {len(profiles)} skill gap profiles\")\n",
                "\n",
                "# Load student data\n",
                "df_students = pd.read_csv(BASE / \"digital_twin_students_1500_cleaned.csv\", low_memory=False)\n",
                "print(f\"Loaded {len(df_students)} student records\")\n",
                "\n",
                "df_features.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Build Feature Matrix"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def build_feature_matrix():\n",
                "    \"\"\"Build comprehensive feature matrix for clustering\"\"\"\n",
                "    features_list = []\n",
                "    student_ids = []\n",
                "    \n",
                "    for _, row in df_features.iterrows():\n",
                "        student_id = row['StudentID']\n",
                "        student_ids.append(student_id)\n",
                "        \n",
                "        feature_vec = []\n",
                "        \n",
                "        # 1. Academic features\n",
                "        academic_cols = ['GPA', 'Attendance', 'FailedCourses', 'CompletedCourses']\n",
                "        for col in academic_cols:\n",
                "            if col in row:\n",
                "                feature_vec.append(row[col] if pd.notna(row[col]) else 0)\n",
                "        \n",
                "        # 2. PCA embedding features (32 dimensions)\n",
                "        emb_cols = [col for col in df_features.columns if col.startswith('emb_pca_')]\n",
                "        for col in emb_cols[:32]:\n",
                "            if col in row:\n",
                "                feature_vec.append(row[col] if pd.notna(row[col]) else 0)\n",
                "        \n",
                "        # 3. Skill gap features\n",
                "        profile = profiles_map.get(student_id, {})\n",
                "        skill_gaps = profile.get('skill_gaps', {})\n",
                "        missing_skills = skill_gaps.get('missing_skills', [])\n",
                "        feature_vec.append(len(missing_skills))\n",
                "        \n",
                "        if 'priority_scores' in skill_gaps and skill_gaps['priority_scores']:\n",
                "            top_priority = max(skill_gaps['priority_scores'].values())\n",
                "            feature_vec.append(top_priority)\n",
                "        else:\n",
                "            feature_vec.append(0)\n",
                "        \n",
                "        # 4. Career prediction one-hot\n",
                "        career_categories = ['Data', 'Machine Learning', 'Cloud', 'Cybersecurity', \n",
                "                           'Software', 'Network', 'DevOps', 'Other']\n",
                "        predicted_career = row.get('predicted_career', 'Other')\n",
                "        for cat in career_categories:\n",
                "            feature_vec.append(1 if predicted_career == cat else 0)\n",
                "        \n",
                "        features_list.append(feature_vec)\n",
                "    \n",
                "    X = np.array(features_list)\n",
                "    return X, student_ids\n",
                "\n",
                "X, student_ids = build_feature_matrix()\n",
                "print(f\"Feature matrix shape: {X.shape}\")\n",
                "print(f\"Features per student: {X.shape[1]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Normalize Features"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "scaler = StandardScaler()\n",
                "X_scaled = scaler.fit_transform(X)\n",
                "print(f\"Scaled feature matrix: {X_scaled.shape}\")\n",
                "print(f\"Mean: {X_scaled.mean():.4f}, Std: {X_scaled.std():.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. KMeans Clustering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run KMeans with 7 clusters\n",
                "n_clusters = 7\n",
                "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
                "cluster_labels = kmeans.fit_predict(X_scaled)\n",
                "\n",
                "print(f\"KMeans clustering complete\")\n",
                "print(f\"\\nCluster distribution:\")\n",
                "cluster_counts = Counter(cluster_labels)\n",
                "for cluster_id, count in sorted(cluster_counts.items()):\n",
                "    print(f\"  Cluster {cluster_id}: {count} students ({count/len(student_ids)*100:.1f}%)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Evaluate Clustering Quality"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Silhouette score\n",
                "silhouette = silhouette_score(X_scaled, cluster_labels)\n",
                "print(f\"Silhouette Score: {silhouette:.3f}\")\n",
                "print(f\"  (Range: -1 to 1, higher is better)\")\n",
                "\n",
                "# Davies-Bouldin score\n",
                "davies_bouldin = davies_bouldin_score(X_scaled, cluster_labels)\n",
                "print(f\"\\nDavies-Bouldin Score: {davies_bouldin:.3f}\")\n",
                "print(f\"  (Lower is better)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Map Clusters to Career Labels"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def map_cluster_to_career(cluster_id, student_indices):\n",
                "    careers = []\n",
                "    for idx in student_indices:\n",
                "        student_id = student_ids[idx]\n",
                "        row = df_features[df_features['StudentID'] == student_id]\n",
                "        if not row.empty:\n",
                "            career = row.iloc[0].get('predicted_career', 'Other')\n",
                "            careers.append(career)\n",
                "    \n",
                "    if careers:\n",
                "        return Counter(careers).most_common(1)[0][0]\n",
                "    return \"Other\"\n",
                "\n",
                "cluster_career_map = {}\n",
                "for cluster_id in range(n_clusters):\n",
                "    cluster_indices = np.where(cluster_labels == cluster_id)[0]\n",
                "    career_label = map_cluster_to_career(cluster_id, cluster_indices)\n",
                "    cluster_career_map[cluster_id] = career_label\n",
                "    print(f\"Cluster {cluster_id} â†’ {career_label}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Visualize Clusters with t-SNE"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# t-SNE dimensionality reduction\n",
                "print(\"Running t-SNE (this may take a minute)...\")\n",
                "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
                "X_tsne = tsne.fit_transform(X_scaled)\n",
                "\n",
                "# Plot\n",
                "plt.figure(figsize=(14, 10))\n",
                "scatter = plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=cluster_labels, \n",
                "                     cmap='tab10', alpha=0.6, s=50, edgecolors='black', linewidth=0.5)\n",
                "plt.colorbar(scatter, label='Cluster')\n",
                "plt.title('Student Clusters (t-SNE Visualization)', fontsize=18, fontweight='bold')\n",
                "plt.xlabel('t-SNE Component 1', fontsize=14)\n",
                "plt.ylabel('t-SNE Component 2', fontsize=14)\n",
                "plt.grid(alpha=0.3, linestyle='--')\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(\"âœ“ t-SNE visualization complete\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. UMAP Visualization (Optional Enhancement)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if UMAP_AVAILABLE:\n",
                "    print(\"Running UMAP (this may take a minute)...\")\n",
                "    \n",
                "    # UMAP dimensionality reduction\n",
                "    reducer = umap.UMAP(n_components=2, random_state=42, n_neighbors=15, min_dist=0.1)\n",
                "    X_umap = reducer.fit_transform(X_scaled)\n",
                "    \n",
                "    # Plot\n",
                "    plt.figure(figsize=(14, 10))\n",
                "    scatter = plt.scatter(X_umap[:, 0], X_umap[:, 1], c=cluster_labels, \n",
                "                         cmap='tab10', alpha=0.6, s=50, edgecolors='black', linewidth=0.5)\n",
                "    plt.colorbar(scatter, label='Cluster')\n",
                "    plt.title('Student Clusters (UMAP Visualization)', fontsize=18, fontweight='bold')\n",
                "    plt.xlabel('UMAP Component 1', fontsize=14)\n",
                "    plt.ylabel('UMAP Component 2', fontsize=14)\n",
                "    plt.grid(alpha=0.3, linestyle='--')\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "    \n",
                "    print(\"âœ“ UMAP visualization complete\")\n",
                "    print(\"\\nðŸ“Š UMAP vs t-SNE:\")\n",
                "    print(\"  - UMAP preserves global structure better\")\n",
                "    print(\"  - UMAP is faster for large datasets\")\n",
                "    print(\"  - t-SNE focuses on local neighborhoods\")\n",
                "else:\n",
                "    print(\"âš  UMAP not available\")\n",
                "    print(\"Install with: pip install umap-learn\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. 3D PCA Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3D PCA for cluster visualization\n",
                "from mpl_toolkits.mplot3d import Axes3D\n",
                "\n",
                "pca_3d = PCA(n_components=3)\n",
                "X_pca_3d = pca_3d.fit_transform(X_scaled)\n",
                "\n",
                "# Create 3D plot\n",
                "fig = plt.figure(figsize=(14, 10))\n",
                "ax = fig.add_subplot(111, projection='3d')\n",
                "\n",
                "scatter = ax.scatter(X_pca_3d[:, 0], X_pca_3d[:, 1], X_pca_3d[:, 2], \n",
                "                     c=cluster_labels, cmap='tab10', alpha=0.6, s=50, \n",
                "                     edgecolors='black', linewidth=0.5)\n",
                "\n",
                "ax.set_xlabel('PC1', fontsize=12)\n",
                "ax.set_ylabel('PC2', fontsize=12)\n",
                "ax.set_zlabel('PC3', fontsize=12)\n",
                "ax.set_title('Student Clusters (3D PCA Visualization)', fontsize=18, fontweight='bold')\n",
                "\n",
                "# Add colorbar\n",
                "cbar = plt.colorbar(scatter, ax=ax, pad=0.1)\n",
                "cbar.set_label('Cluster', fontsize=12)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(f\"âœ“ 3D PCA visualization complete\")\n",
                "print(f\"Explained variance: {pca_3d.explained_variance_ratio_.sum():.2%}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Compute Similar Students"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compute cosine similarity\n",
                "print(\"Computing similarity matrix...\")\n",
                "similarity_matrix = cosine_similarity(X_scaled)\n",
                "\n",
                "# Find top 10 similar students\n",
                "similar_students = {}\n",
                "for i, student_id in enumerate(student_ids):\n",
                "    similarities = similarity_matrix[i]\n",
                "    top_indices = np.argsort(similarities)[::-1][1:11]\n",
                "    similar_ids = [student_ids[idx] for idx in top_indices]\n",
                "    similar_students[student_id] = similar_ids\n",
                "\n",
                "print(f\"âœ“ Computed similarities for {len(similar_students)} students\")\n",
                "print(f\"\\nExample - Similar students to S0001:\")\n",
                "print(similar_students.get('S0001', [])[:5])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. Generate Cluster Profiles"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cluster_profiles = {}\n",
                "\n",
                "for cluster_id in range(n_clusters):\n",
                "    cluster_indices = np.where(cluster_labels == cluster_id)[0]\n",
                "    cluster_student_ids = [student_ids[idx] for idx in cluster_indices]\n",
                "    \n",
                "    cluster_students = df_students[df_students['StudentID'].isin(cluster_student_ids)]\n",
                "    \n",
                "    avg_gpa = cluster_students['GPA'].mean() if 'GPA' in cluster_students else 0\n",
                "    avg_attendance = cluster_students['Attendance'].mean() if 'Attendance' in cluster_students else 0\n",
                "    \n",
                "    # Get top missing skills\n",
                "    all_missing_skills = []\n",
                "    for sid in cluster_student_ids:\n",
                "        profile = profiles_map.get(sid, {})\n",
                "        missing = profile.get('skill_gaps', {}).get('missing_skills', [])\n",
                "        all_missing_skills.extend(missing[:5])\n",
                "    \n",
                "    top_missing = Counter(all_missing_skills).most_common(10)\n",
                "    \n",
                "    cluster_profiles[cluster_career_map[cluster_id]] = {\n",
                "        \"cluster_id\": int(cluster_id),\n",
                "        \"career_label\": cluster_career_map[cluster_id],\n",
                "        \"member_count\": len(cluster_student_ids),\n",
                "        \"avg_gpa\": float(avg_gpa),\n",
                "        \"avg_attendance\": float(avg_attendance),\n",
                "        \"top_missing_skills\": [skill for skill, count in top_missing]\n",
                "    }\n",
                "\n",
                "# Display cluster profiles\n",
                "pd.DataFrame(cluster_profiles).T"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 12. Save Outputs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save clusters.json\n",
                "clusters_output = {}\n",
                "for cluster_id in range(n_clusters):\n",
                "    cluster_indices = np.where(cluster_labels == cluster_id)[0]\n",
                "    cluster_student_ids = [student_ids[idx] for idx in cluster_indices]\n",
                "    career_label = cluster_career_map[cluster_id]\n",
                "    clusters_output[career_label] = cluster_student_ids\n",
                "\n",
                "with open(BASE / \"clusters.json\", \"w\") as f:\n",
                "    json.dump(clusters_output, f, indent=2)\n",
                "print(\"âœ“ Saved clusters.json\")\n",
                "\n",
                "# Save similar_students.json\n",
                "with open(BASE / \"similar_students.json\", \"w\") as f:\n",
                "    json.dump(similar_students, f, indent=2)\n",
                "print(\"âœ“ Saved similar_students.json\")\n",
                "\n",
                "# Save cluster_profiles.json\n",
                "with open(BASE / \"cluster_profiles.json\", \"w\") as f:\n",
                "    json.dump(cluster_profiles, f, indent=2)\n",
                "print(\"âœ“ Saved cluster_profiles.json\")\n",
                "\n",
                "# Save cluster assignments\n",
                "cluster_assignments = {\n",
                "    student_ids[i]: {\n",
                "        \"cluster_id\": int(cluster_labels[i]),\n",
                "        \"cluster_label\": cluster_career_map[cluster_labels[i]]\n",
                "    }\n",
                "    for i in range(len(student_ids))\n",
                "}\n",
                "\n",
                "with open(BASE / \"cluster_assignments.json\", \"w\") as f:\n",
                "    json.dump(cluster_assignments, f, indent=2)\n",
                "print(\"âœ“ Saved cluster_assignments.json\")\n",
                "\n",
                "print(\"\\nâœ… All outputs saved successfully!\")\n",
                "print(f\"\\nðŸ“Š Summary:\")\n",
                "print(f\"  - {len(student_ids)} students clustered\")\n",
                "print(f\"  - {n_clusters} clusters created\")\n",
                "print(f\"  - Silhouette score: {silhouette:.3f}\")\n",
                "print(f\"  - Similarity network: {len(similar_students)} students\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}